{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383f03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/derekhuang/Documents/Research/sequence_similarity_search/classes')\n",
    "sys.path.insert(1, '/Users/derekhuang/Documents/Research/fast-soft-sort/fast_soft_sort')\n",
    "from data_classes import BERTDataset\n",
    "from dist_perm import DistPerm\n",
    "import utils\n",
    "from pytorch_ops import soft_rank\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "class AnchorNet(nn.Module):\n",
    "    def __init__(self, num_anchs, d, k):\n",
    "        super(AnchorNet, self).__init__()\n",
    "        self.anchors = nn.Linear(d, num_anchs)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, data, query):\n",
    "        data_rank = torch.clamp(soft_rank(self.anchors(data), direction=\"DESCENDING\", regularization_strength=.001), max=k)\n",
    "#         data_rank = soft_rank(self.anchors(data), direction=\"DESCENDING\")\n",
    "        \n",
    "        query_rank = torch.clamp(soft_rank(self.anchors(query), direction=\"DESCENDING\", regularization_strength=.001), max=k)\n",
    "#         query_rank = soft_rank(self.anchors(query), direction=\"DESCENDING\")\n",
    "        \n",
    "        out = self.softmax(torch.matmul(query_rank, data_rank.T))\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825c3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20000\n",
    "D = 128\n",
    "num_queries = 3200\n",
    "num_anchors = 128\n",
    "R = 100\n",
    "k = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561d9e5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([685571, 128])\n",
      "torch.Size([100, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "file_q = '../datasets/Q.pt'\n",
    "file_db = '../datasets/D.pt'\n",
    "data_source = BERTDataset(file_q, file_db, n)\n",
    "db = data_source.generate_db()\n",
    "data = np.array(db).astype(np.float32)\n",
    "queries = data_source.generate_queries(num_queries)\n",
    "quers = np.array(queries).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15dd4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_l2 = NearestNeighbors()\n",
    "index_l2.fit(data)\n",
    "true = torch.tensor(index_l2.kneighbors(quers, n_neighbors=1)[1])\n",
    "truth = torch.nn.functional.one_hot(true.squeeze(), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c04c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, itertools\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "\n",
    "def dataset_split(dataset, train_frac):\n",
    "    length = len(dataset)\n",
    "   \n",
    "    train_length = int(length * train_frac)\n",
    "    valid_length = int((length - train_length) / 2)\n",
    "    test_length  = length - train_length - valid_length\n",
    "\n",
    "    sets = random_split(dataset, (train_length, valid_length, test_length))\n",
    "    dataset = {name: set for name, set in zip(('train', 'valid', 'test'), sets)}\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a098c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits fine in mem\n",
    "batch_size=3200\n",
    "train_split = .8 \n",
    "\n",
    "query_data = []\n",
    "for i in range(queries.shape[0]):\n",
    "    query_data.append([queries[i], true[i]])\n",
    "\n",
    "query_datasets = dataset_split(query_data, train_split)\n",
    "query_loader = torch.utils.data.DataLoader(dataset=query_datasets['train'], \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=query_datasets['test'], \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "model = AnchorNet(num_anchors, D, k)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca65b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 9.4589, recall_test: 0.4656\n",
      "Epoch [2], Loss: 9.4561, recall_test: 0.4656\n",
      "Epoch [3], Loss: 9.4539, recall_test: 0.4906\n",
      "Epoch [4], Loss: 9.4478, recall_test: 0.4844\n",
      "Epoch [5], Loss: 9.4424, recall_test: 0.4844\n",
      "Epoch [6], Loss: 9.4368, recall_test: 0.4906\n",
      "Epoch [7], Loss: 9.4317, recall_test: 0.4906\n",
      "Epoch [8], Loss: 9.4301, recall_test: 0.5000\n",
      "Epoch [9], Loss: 9.4298, recall_test: 0.5031\n",
      "Epoch [10], Loss: 9.4259, recall_test: 0.5062\n",
      "Epoch [11], Loss: 9.4219, recall_test: 0.5188\n",
      "Epoch [12], Loss: 9.4209, recall_test: 0.5281\n",
      "Epoch [13], Loss: 9.4141, recall_test: 0.5375\n",
      "Epoch [14], Loss: 9.4087, recall_test: 0.5375\n",
      "Epoch [15], Loss: 9.4069, recall_test: 0.5344\n",
      "Epoch [16], Loss: 9.4076, recall_test: 0.5250\n",
      "Epoch [17], Loss: 9.4085, recall_test: 0.5281\n",
      "Epoch [18], Loss: 9.4002, recall_test: 0.5344\n",
      "Epoch [19], Loss: 9.3956, recall_test: 0.5344\n",
      "Epoch [20], Loss: 9.3935, recall_test: 0.5375\n",
      "Epoch [21], Loss: 9.3879, recall_test: 0.5312\n",
      "Epoch [22], Loss: 9.3884, recall_test: 0.5312\n",
      "Epoch [23], Loss: 9.3871, recall_test: 0.5312\n",
      "Epoch [24], Loss: 9.3878, recall_test: 0.5375\n",
      "Epoch [25], Loss: 9.3859, recall_test: 0.5375\n",
      "Epoch [26], Loss: 9.3862, recall_test: 0.5406\n",
      "Epoch [27], Loss: 9.3800, recall_test: 0.5500\n",
      "Epoch [28], Loss: 9.3777, recall_test: 0.5469\n",
      "Epoch [29], Loss: 9.3762, recall_test: 0.5500\n",
      "Epoch [30], Loss: 9.3741, recall_test: 0.5500\n",
      "Epoch [31], Loss: 9.3715, recall_test: 0.5406\n",
      "Epoch [32], Loss: 9.3747, recall_test: 0.5500\n",
      "Epoch [33], Loss: 9.3704, recall_test: 0.5469\n",
      "Epoch [34], Loss: 9.3693, recall_test: 0.5469\n",
      "Epoch [35], Loss: 9.3692, recall_test: 0.5469\n",
      "Epoch [36], Loss: 9.3671, recall_test: 0.5500\n",
      "Epoch [37], Loss: 9.3636, recall_test: 0.5437\n",
      "Epoch [38], Loss: 9.3644, recall_test: 0.5437\n",
      "Epoch [39], Loss: 9.3650, recall_test: 0.5500\n",
      "Epoch [40], Loss: 9.3585, recall_test: 0.5500\n",
      "Epoch [41], Loss: 9.3564, recall_test: 0.5563\n",
      "Epoch [42], Loss: 9.3550, recall_test: 0.5531\n",
      "Epoch [43], Loss: 9.3513, recall_test: 0.5531\n",
      "Epoch [44], Loss: 9.3506, recall_test: 0.5531\n",
      "Epoch [45], Loss: 9.3473, recall_test: 0.5531\n",
      "Epoch [46], Loss: 9.3454, recall_test: 0.5531\n",
      "Epoch [47], Loss: 9.3467, recall_test: 0.5563\n",
      "Epoch [48], Loss: 9.3465, recall_test: 0.5625\n",
      "Epoch [49], Loss: 9.3430, recall_test: 0.5687\n",
      "Epoch [50], Loss: 9.3397, recall_test: 0.5719\n",
      "Epoch [51], Loss: 9.3391, recall_test: 0.5687\n",
      "Epoch [52], Loss: 9.3406, recall_test: 0.5719\n",
      "Epoch [53], Loss: 9.3411, recall_test: 0.5781\n",
      "Epoch [54], Loss: 9.3385, recall_test: 0.5844\n",
      "Epoch [55], Loss: 9.3377, recall_test: 0.5875\n",
      "Epoch [56], Loss: 9.3325, recall_test: 0.5875\n",
      "Epoch [57], Loss: 9.3334, recall_test: 0.5875\n",
      "Epoch [58], Loss: 9.3336, recall_test: 0.5875\n",
      "Epoch [59], Loss: 9.3351, recall_test: 0.5906\n",
      "Epoch [60], Loss: 9.3363, recall_test: 0.5750\n",
      "Epoch [61], Loss: 9.3407, recall_test: 0.5875\n",
      "Epoch [62], Loss: 9.3371, recall_test: 0.5875\n",
      "Epoch [63], Loss: 9.3385, recall_test: 0.5906\n",
      "Epoch [64], Loss: 9.3392, recall_test: 0.6031\n",
      "Epoch [65], Loss: 9.3358, recall_test: 0.6062\n",
      "Epoch [66], Loss: 9.3336, recall_test: 0.6062\n",
      "Epoch [67], Loss: 9.3308, recall_test: 0.5969\n",
      "Epoch [68], Loss: 9.3306, recall_test: 0.6000\n",
      "Epoch [69], Loss: 9.3265, recall_test: 0.6000\n",
      "Epoch [70], Loss: 9.3250, recall_test: 0.6031\n",
      "Epoch [71], Loss: 9.3255, recall_test: 0.6031\n",
      "Epoch [72], Loss: 9.3213, recall_test: 0.6062\n",
      "Epoch [73], Loss: 9.3189, recall_test: 0.5969\n",
      "Epoch [74], Loss: 9.3189, recall_test: 0.6031\n",
      "Epoch [75], Loss: 9.3180, recall_test: 0.6125\n",
      "Epoch [76], Loss: 9.3187, recall_test: 0.6094\n",
      "Epoch [77], Loss: 9.3200, recall_test: 0.6125\n",
      "Epoch [78], Loss: 9.3160, recall_test: 0.6062\n",
      "Epoch [79], Loss: 9.3145, recall_test: 0.6156\n",
      "Epoch [80], Loss: 9.3129, recall_test: 0.6156\n",
      "Epoch [81], Loss: 9.3099, recall_test: 0.6188\n",
      "Epoch [82], Loss: 9.3103, recall_test: 0.6188\n",
      "Epoch [83], Loss: 9.3106, recall_test: 0.6250\n",
      "Epoch [84], Loss: 9.3093, recall_test: 0.6312\n",
      "Epoch [85], Loss: 9.3079, recall_test: 0.6344\n",
      "Epoch [86], Loss: 9.3079, recall_test: 0.6344\n",
      "Epoch [87], Loss: 9.3084, recall_test: 0.6312\n",
      "Epoch [88], Loss: 9.3083, recall_test: 0.6312\n",
      "Epoch [89], Loss: 9.3087, recall_test: 0.6281\n",
      "Epoch [90], Loss: 9.3076, recall_test: 0.6281\n",
      "Epoch [91], Loss: 9.3068, recall_test: 0.6281\n",
      "Epoch [92], Loss: 9.3043, recall_test: 0.6250\n",
      "Epoch [93], Loss: 9.3056, recall_test: 0.6250\n",
      "Epoch [94], Loss: 9.3040, recall_test: 0.6281\n",
      "Epoch [95], Loss: 9.3060, recall_test: 0.6250\n",
      "Epoch [96], Loss: 9.3060, recall_test: 0.6250\n",
      "Epoch [97], Loss: 9.3066, recall_test: 0.6219\n",
      "Epoch [98], Loss: 9.3063, recall_test: 0.6281\n",
      "Epoch [99], Loss: 9.3028, recall_test: 0.6312\n",
      "Epoch [100], Loss: 9.3010, recall_test: 0.6344\n",
      "Epoch [101], Loss: 9.3005, recall_test: 0.6375\n",
      "Epoch [102], Loss: 9.3001, recall_test: 0.6406\n",
      "Epoch [103], Loss: 9.2985, recall_test: 0.6375\n",
      "Epoch [104], Loss: 9.2996, recall_test: 0.6438\n",
      "Epoch [105], Loss: 9.2950, recall_test: 0.6469\n",
      "Epoch [106], Loss: 9.2927, recall_test: 0.6500\n",
      "Epoch [107], Loss: 9.2921, recall_test: 0.6438\n",
      "Epoch [108], Loss: 9.2952, recall_test: 0.6469\n",
      "Epoch [109], Loss: 9.2971, recall_test: 0.6469\n",
      "Epoch [110], Loss: 9.2963, recall_test: 0.6438\n",
      "Epoch [111], Loss: 9.2968, recall_test: 0.6469\n",
      "Epoch [112], Loss: 9.2963, recall_test: 0.6500\n",
      "Epoch [113], Loss: 9.2954, recall_test: 0.6469\n",
      "Epoch [114], Loss: 9.2939, recall_test: 0.6531\n",
      "Epoch [115], Loss: 9.2912, recall_test: 0.6562\n",
      "Epoch [116], Loss: 9.2902, recall_test: 0.6562\n",
      "Epoch [117], Loss: 9.2880, recall_test: 0.6531\n",
      "Epoch [118], Loss: 9.2881, recall_test: 0.6531\n",
      "Epoch [119], Loss: 9.2870, recall_test: 0.6500\n",
      "Epoch [120], Loss: 9.2883, recall_test: 0.6469\n",
      "Epoch [121], Loss: 9.2872, recall_test: 0.6500\n",
      "Epoch [122], Loss: 9.2879, recall_test: 0.6500\n",
      "Epoch [123], Loss: 9.2881, recall_test: 0.6500\n",
      "Epoch [124], Loss: 9.2838, recall_test: 0.6469\n",
      "Epoch [125], Loss: 9.2830, recall_test: 0.6562\n",
      "Epoch [126], Loss: 9.2816, recall_test: 0.6531\n",
      "Epoch [127], Loss: 9.2841, recall_test: 0.6531\n",
      "Epoch [128], Loss: 9.2826, recall_test: 0.6562\n",
      "Epoch [129], Loss: 9.2829, recall_test: 0.6531\n",
      "Epoch [130], Loss: 9.2820, recall_test: 0.6531\n",
      "Epoch [131], Loss: 9.2826, recall_test: 0.6531\n",
      "Epoch [132], Loss: 9.2829, recall_test: 0.6562\n",
      "Epoch [133], Loss: 9.2805, recall_test: 0.6562\n",
      "Epoch [134], Loss: 9.2811, recall_test: 0.6500\n",
      "Epoch [135], Loss: 9.2788, recall_test: 0.6469\n",
      "Epoch [136], Loss: 9.2785, recall_test: 0.6500\n",
      "Epoch [137], Loss: 9.2786, recall_test: 0.6500\n",
      "Epoch [138], Loss: 9.2784, recall_test: 0.6531\n",
      "Epoch [139], Loss: 9.2786, recall_test: 0.6500\n",
      "Epoch [140], Loss: 9.2766, recall_test: 0.6594\n",
      "Epoch [141], Loss: 9.2780, recall_test: 0.6531\n",
      "Epoch [142], Loss: 9.2782, recall_test: 0.6531\n",
      "Epoch [143], Loss: 9.2757, recall_test: 0.6469\n",
      "Epoch [144], Loss: 9.2728, recall_test: 0.6438\n",
      "Epoch [145], Loss: 9.2717, recall_test: 0.6469\n",
      "Epoch [146], Loss: 9.2686, recall_test: 0.6531\n",
      "Epoch [147], Loss: 9.2654, recall_test: 0.6594\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    for i, (q, l) in enumerate(query_loader):  \n",
    "        outputs = model(db,queries)\n",
    "        loss = criterion(outputs, true.squeeze())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#     print('Loss: {:.4f}'.format(loss.item()))\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for q, l in test_loader:\n",
    "                outputs = model(db,q)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "#                 print(predicted.shape)\n",
    "                total += l.size(0)\n",
    "#                 print(l.size(0))\n",
    "                correct += (predicted == l.flatten()).sum().item()\n",
    "\n",
    "            print ('Epoch [{}], Loss: {:.4f}, recall_test: {:.4f}'\n",
    "                   .format(epoch+1, loss.item(), correct / total))\n",
    "\n",
    "# # Save the model checkpoint\n",
    "# torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
